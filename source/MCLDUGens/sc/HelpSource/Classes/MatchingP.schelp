CLASS:: MatchingP
summary:: Real time sparse representation
categories:: UGens>Analysis
related:: Classes/FFT

DESCRIPTION::
This UGen analyses frames of input audio, a bit like link::Classes/FFT:: does, but using the assumption that most of the energy in each audio frame can be represented as a combination of a small number of "atoms". This is achieved using  STRONG::Matching Pursuit::, which is a standard technique in the field of EMPHASIS::sparse representations::.

You must supply a "dictionary" of atoms, given as a Buffer. Each channel of the Buffer is one atom (this means the atoms all have to be the same length - but zero-padding is OK).

This analysis is less efficient than FFT, so be careful of your CPU usage, and use small, short dictionaries if possible. It also outputs a lot of multichannel data.

CLASSMETHODS::
METHOD:: ar, kr
argument:: dict
The Buffer which holds the atoms. NOTE: in most use cases, the atoms should typically all be normalised so that they all have the same L2-norm (see examples below).
argument:: in
The input signal.
argument:: dictsize
The number of atoms (channels) in the dict.
argument:: ntofind
Specifies the number of activations to find in each frame - i.e. the number of atoms that are assumed to be "on" in each frame.
argument:: hop
The amount of hop between frames, expressed as a proportion of the dict length (like in link::Classes/FFT::). Maximum is 1.
argument:: method
Reserved. (Doesn't currently do anything.)

returns::
TELETYPE::[trigger, residual, activ0, activ1, activ2, ...]:: where TELETYPE::trigger:: indicates the moment when a frame has been processed, TELETYPE::residual:: gives the signal that remains after subtracting the contribution from the selected atoms, and TELETYPE::activ0, activ1, activ2, ...:: are the activation strengths of each element in the dictionary (in order).

Typically, exactly TELETYPE::ntofind:: of the activation strengths will be nonzero at any point, though it could be fewer.

EXAMPLES::

NOTE: because of the large number of channels involved, you may need to increase your server's number of wire-buffers (these are signal buffers internal to a synthdef):
code::
s.quit
s.options.numWireBufs = 256;
s.boot
::

In this example we make a simple dictionary which happens to be quite similar to an un-windowed FFT basis, and then analyse it.

code::
~dictlen = 128;
~dictsize = 64; //8;
~dictarr = ~dictsize.collect{|i|  sin(2pi*(i+1)*(1..~dictlen)/~dictlen)  };
~dictarr = ~dictarr.collect{|a| a / a.squared.sum.sqrt }    // Here is where we L2 normalise all the atoms
// The dictionary buffer:
~dict = Buffer.loadCollection(s, ~dictarr.flop.flat, ~dictsize);
~dict.plot

// We'll output the activations to a bus too
~actbus = Bus.audio(s, ~dictsize);

(
x={
	var son, outputs, trig, residual, acts, resynth, delayedson;
	// Homemade example which should be perfectly recoverable:
	son = (PlayBuf.ar(~dictsize, ~dict, loop: 1) * ([0.1, 0.3, 0.5]++{0}.dup(~dictsize-3))).sum;
	// Or you could try one of these:
	//son = PinkNoise.ar * LFPulse.kr(1);
	//son = Pulse.ar(200 * SinOsc.kr(0.3).exprange(0.9, 1.1));
	//son = (PlayBuf.ar(~dictsize, ~dict, MouseX.kr(0.1, 2, 1). loop: 1) * ([0.1, 0.3, 0.5]++{0}.dup(~dictsize-3))).sum;
	outputs = MatchingP.ar(~dict, son, ~dictsize, ntofind:2);
	trig = outputs[0];
	residual = outputs[1];
	acts = outputs[2..];
	Out.ar(~actbus, acts);

	// In the next part we'll resynthesise the sound.
	// But you might like to mangle the 'acts' data to apply interesting FX:
	//acts = acts.collect{|a| a * 3 * SinOsc.ar(exprand(0.1, 10))};
	//acts = acts.collect{|a| a * 3 * SinOsc.ar(LFNoise1.kr(10).exprange(0.1, 10))};
	//acts = acts.collect{|a| DelayN.ar(a, 0.1, LFNoise1.kr(0.1).range(0, 0.1))};
	//acts = acts.reverse;
	//acts = acts.scramble;

	resynth = MatchingPResynth.ar(~dict, trig, *acts);
	delayedson = DelayN.ar(son, delaytime:BufDur.ir(~dict));
	//Amplitude.ar(resynth - delayedson, 0.1, 1).poll(1, "amplitude of reconstruction error");
	[delayedson * 0.0001, residual + resynth * 0.1];
}.play
)

~actbus.scope

s.scope

::
